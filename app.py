import streamlit as st
from streamlit_gsheets import GSheetsConnection
import pandas as pd
from datetime import datetime, timedelta
import google.generativeai as genai
from PIL import Image
import json
import re
import plotly.graph_objects as go

# --- 1. Âü∫Êú¨Ë®≠ÂÆö ---
GOAL = 100000000 
URL = "https://docs.google.com/spreadsheets/d/1-Elv0TZJb6dVwHoGCx0fQinN2B1KYPOwWt0aWJEa_Is/edit"

st.set_page_config(page_title="Wealth Navigator PRO", page_icon="üìà", layout="wide")

# --- 2. Â§ñÈÉ®ÈÄ£Êê∫Ë®≠ÂÆö ---
try:
    genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
    model = genai.GenerativeModel('models/gemini-1.5-flash')
except:
    st.error("APIË®≠ÂÆö„ÇíÁ¢∫Ë™ç„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ")
    st.stop()

conn = st.connection("gsheets", type=GSheetsConnection)

if 'analyzed' not in st.session_state:
    st.session_state.analyzed = False
if 'ocr_data' not in st.session_state:
    st.session_state.ocr_data = {"cash": 0, "spot": 0, "margin": 0}

# --- 3. AIÊ©üËÉΩ ---
def perform_ai_analysis(up_file):
    p = 'ÊäΩÂá∫Ôºö{"cash": Êï∞ÂÄ§, "spot": Êï∞ÂÄ§, "margin": Êï∞ÂÄ§}'
    try:
        img = Image.open(up_file)
        res = model.generate_content([p, img])
        j_str = re.search(r'\{.*\}', res.text, re.DOTALL).group()
        return json.loads(j_str)
    except: return None

@st.cache_data(ttl=3600)
def get_market_briefing(d_str):
    p = f"‰ªäÊó•„ÅØ{d_str}„ÄÇÈÄ±Êòé„Åë„ÅÆÊó•Êú¨Ê†™Ê±∫ÁÆó‰∫àÂÆö„ÄÅÈáçË¶ÅÊåáÊ®ô„ÄÅüö®Ê≥®ÁõÆ„Ç§„Éô„É≥„Éà„ÇíÁ∞°ÊΩî„Å´„Åæ„Å®„ÇÅ„Å¶„ÄÇÊäïË≥áÂä©Ë®Ä„ÅØ‰∏çË¶Å„ÄÇ"
    try:
        res = model.generate_content(p)
        return res.text if res.text else "ÊÉÖÂ†±„ÅÆÂèñÂæó„ÇíÂà∂Èôê‰∏≠"
    except: return "üí° Â∏ÇÂ†¥„Éá„Éº„Çø„ÇíÁ¢∫Ë™ç‰∏≠„Åß„Åô„ÄÇ„É™„É≠„Éº„Éâ„Çí„ÅäË©¶„Åó„Åè„Å†„Åï„ÅÑ„ÄÇ"

# --- 4. „Éá„Éº„ÇøË™≠„ÅøËæº„Åø ---
df_raw = pd.DataFrame()
try:
    df_raw = conn.read(spreadsheet=URL, ttl=0)
except:
    st.warning("„Çπ„Éó„É¨„ÉÉ„Éâ„Ç∑„Éº„ÉàÊé•Á∂öÂæÖ„Å°...")

# --- 5. „É°„Ç§„É≥Ë°®Á§∫ ---
st.title("üöÄ Wealth Navigator PRO")

if not df_raw.empty:
    # „Éá„Éº„Çø„ÅÆÂæπÂ∫ïÁöÑ„Å™„ÇØ„É¨„É≥„Ç∏„É≥„Ç∞
    df_raw['Êó•‰ªò'] = pd.to_datetime(df_raw['Êó•‰ªò'], errors='coerce')
    df_raw = df_raw.dropna(subset=['Êó•‰ªò'])
    df = df_raw.sort_values('Êó•‰ªò').drop_duplicates('Êó•‰ªò', keep='last').reset_index(drop=True)
    
    latest = df.iloc[-1]
    ld, total = latest['Êó•‰ªò'], latest['Á∑èË≥áÁî£']
    
    # 1. ÊåáÊ®ôË®àÁÆóÔºà„Ç®„É©„ÉºËÄêÊÄßÂº∑ÂåñÔºâ
    d_diff = total - df.iloc[-2]['Á∑èË≥áÁî£'] if len(df) > 1 else 0
    tm_df = df[df['Êó•‰ªò'].dt.to_period('M') == ld.to_period('M')]
    tm_diff = total - tm_df.iloc[0]['Á∑èË≥áÁî£'] if not tm_df.empty else 0
    
    # „ÉÄ„ÉÉ„Ç∑„É•„Éú„Éº„Éâ
    st.subheader("üìä Ë≥áÁî£Áä∂Ê≥Å„ÉÄ„ÉÉ„Ç∑„É•„Éú„Éº„Éâ")
    cols = st.columns([1.2, 1, 1, 1, 1])
    with cols[0]:
        st.metric("ÁèæÂú®„ÅÆÁ∑èË≥áÁî£", f"¬•{int(total):,}")
        st.caption(f"‚î£ ÁèæÁâ©Ë≥áÁî£ÊôÇ‰æ°Á∑èÈ°ç: ¬•{int(latest['ÁèæÁâ©ÊôÇ‰æ°Á∑èÈ°ç']):,}")
        st.caption(f"‚î£ ‰ø°Áî®‰øùÊúâË≥áÁî£ÊêçÁõä: ¬•{int(latest['‰ø°Áî®Ë©ï‰æ°ÊêçÁõä']):+,}")
        st.caption(f"‚îó ÁèæÁâ©ÂèñÂæó‰ΩôÂäõ: ¬•{int(latest['ÁèæÁâ©Ë≤∑‰ªò‰ΩôÂäõ']):,}")
    
    cols[1].metric("1ÂÑÑÂÜÜ„Åæ„Åß", f"¬•{int(GOAL - total):,}")
    cols[2].metric("ÂâçÊó•ÊØî", f"¬•{int(d_diff):,}", delta=f"{int(d_diff):+,}")
    cols[3].metric(f"{ld.month}ÊúàÂèéÊîØ", f"¬•{int(tm_diff):,}", delta=f"{int(tm_diff):+,}")
    cols[4].metric("ÁõÆÊ®ôÈÅîÊàêÁéá", f"{total/GOAL:.2%}")
    
    st.progress(max(0.0, min(float(total / GOAL), 1.0)))

    # 2. AI„Éû„Éº„Ç±„ÉÉ„Éà„ÉÄ„Ç§„Ç∏„Çß„Çπ„ÉàÔºàÁã¨Á´ã„Éñ„É≠„ÉÉ„ÇØ„ÅßÁ¢∫ÂÆü„Å´Ë°®Á§∫Ôºâ
    st.divider()
    st.subheader("üóìÔ∏è Êú¨Êó•„ÅÆ„Éû„Éº„Ç±„ÉÉ„Éà„Éª„ÉÄ„Ç§„Ç∏„Çß„Çπ„Éà")
    today_key = datetime.now().strftime('%Y-%m-%d')
    st.markdown(get_market_briefing(today_key))

    # 3. „Ç∞„É©„Éï„Çª„ÇØ„Ç∑„Éß„É≥Ôºà„Éá„Éº„Çø„Éï„Ç£„É´„Çø„É™„É≥„Ç∞„ÇíÂÆâÂÖ®„Å´Ôºâ
    st.divider()
    vc, uc = st.columns([3, 1])
    with vc: st.write("### üèîÔ∏è Ë≥áÁî£ÊàêÈï∑„Éà„É¨„É≥„Éâ")
    with uc: v_mode = st.radio("Ë°®Á§∫", ["Êó•", "ÈÄ±", "Êúà"], horizontal=True)

    try:
        if v_mode == "Êó•":
            p_df = df[df['Êó•‰ªò'] >= (ld - timedelta(days=30))].copy()
            xf = "%m/%d"
        elif v_mode == "ÈÄ±":
            p_df = df.set_index('Êó•‰ªò').resample('W').last().dropna().reset_index()
            xf = "%m/%d"
        else:
            p_df = df.set_index('Êó•‰ªò').resample('M').last().dropna().reset_index()
            xf = "%y/%m"
        
        if p_df.empty: p_df = df.copy()

        ymax = p_df['Á∑èË≥áÁî£'].max() * 1.15 if not p_df.empty else 1000000
        fig = go.Figure()
        fig.add_trace(go.Scatter(
            x=p_df['Êó•‰ªò'], y=p_df['Á∑èË≥áÁî£'], fill='tozeroy', 
            line=dict(color='#007BFF', width=4), fillcolor='rgba(0, 123, 255, 0.15)',
            mode='lines+markers' if len(p_df) < 20 else 'lines'
        ))
        fig.update_layout(
            template="plotly_dark", height=400, margin=dict(l=50, r=20, t=20, b=50),
            xaxis=dict(tickformat=xf, type='date'),
            yaxis=dict(range=[0, ymax], tickformat=",d"),
            hovermode="x unified"
        )
        st.plotly_chart(fig, use_container_width=True)
    except:
        st.error("„Ç∞„É©„Éï„ÅÆÁîüÊàê„Å´Â§±Êïó„Åó„Åæ„Åó„Åü„ÄÇÂçÅÂàÜ„Å™„Éá„Éº„Çø„ÅåËìÑÁ©ç„Åï„Çå„Çã„Åæ„Åß„ÅäÂæÖ„Å°„Åè„Å†„Åï„ÅÑ„ÄÇ")
else:
    st.info("„Éá„Éº„Çø„Åå„ÅÇ„Çä„Åæ„Åõ„Çì„ÄÇÊùæ‰∫ïË®ºÂà∏„ÅÆË≥áÁî£„Çπ„ÇØ„Ç∑„Éß„Çí„Ç¢„ÉÉ„Éó„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ")

# --- 6. Êõ¥Êñ∞„Éï„Ç©„Éº„É† ---
st.divider()
st.subheader("üì∏ Ë≥áÁî£Áä∂Ê≥Å„ÇíÊõ¥Êñ∞")
up_file = st.file_uploader("„Çπ„ÇØ„Ç∑„Éß„ÇíÈÅ∏Êäû", type=['png', 'jpg', 'jpeg'])

if st.button("AIËß£Êûê„ÇíÂÆüË°å"):
    if up_file:
        with st.spinner('Ëß£Êûê‰∏≠...'):
            res = perform_ai_analysis(up_file)
            if res:
                st.session_state.ocr_data = res
                st.session_state.analyzed = True
                st.success("ÊàêÂäüÔºÅÂÜÖÂÆπ„ÇíÁ¢∫Ë™ç„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ")

if st.session_state.analyzed:
    with st.form("edit_form"):
        c1, c2, c3 = st.columns(3)
        ocr = st.session_state.ocr_data
        n_c = c1.number_input("ÁèæÁâ©ÂèñÂæó‰ΩôÂäõ", value=int(ocr.get('cash', 0)))
        n_s = c2.number_input("ÁèæÁâ©Ë≥áÁî£ÊôÇ‰æ°Á∑èÈ°ç", value=int(ocr.get('spot', 0)))
        n_m = c3.number_input("‰ø°Áî®‰øùÊúâË≥áÁî£ÊêçÁõä", value=int(ocr.get('margin', 0)))
        if st.form_submit_button("Ë®òÈå≤„Åô„Çã"):
            today_str = datetime.now().strftime('%Y/%m/%d')
            t_v = n_c + n_s + n_m
            ent = pd.DataFrame([{"Êó•‰ªò": today_str, "ÁèæÁâ©Ë≤∑‰ªò‰ΩôÂäõ": n_c, "ÁèæÁâ©ÊôÇ‰æ°Á∑èÈ°ç": n_s, "‰ø°Áî®Ë©ï‰æ°ÊêçÁõä": n_m, "Á∑èË≥áÁî£": t_v, "1ÂÑÑÂÜÜ„Åæ„Åß„ÅÆÊÆã„Çä": GOAL - t_v}])
            try:
                out = pd.concat([df_raw, ent], ignore_index=True) if not df_raw.empty else ent
                out['Êó•‰ªò'] = pd.to_datetime(out['Êó•‰ªò'])
                out = out.sort_values('Êó•‰ªò').drop_duplicates('Êó•‰ªò', keep='last')
                out['Êó•‰ªò'] = out['Êó•‰ªò'].dt.strftime('%Y/%m/%d')
                conn.update(spreadsheet=URL, data=out)
                st.balloons()
                st.session_state.analyzed = False
                st.rerun()
            except Exception as e:
                st.error(f"‰øùÂ≠òÂ§±Êïó: {e}")
