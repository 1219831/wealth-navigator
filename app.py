import streamlit as st
from streamlit_gsheets import GSheetsConnection
import pandas as pd
from datetime import datetime, timedelta
import google.generativeai as genai
from PIL import Image
import json
import re
import plotly.graph_objects as go

# --- 1. Âü∫Êú¨Ë®≠ÂÆö ---
GOAL = 100000000 
URL = "https://docs.google.com/spreadsheets/d/1-Elv0TZJb6dVwHoGCx0fQinN2B1KYPOwWt0aWJEa_Is/edit"

st.set_page_config(page_title="Wealth Nav", page_icon="üìà", layout="wide")

# --- 2. Â§ñÈÉ®ÈÄ£Êê∫ (Êé•Á∂ö„ÉÅ„Çß„ÉÉ„ÇØÂº∑ÂåñÁâà) ---
def init_gemini():
    try:
        # Secret„Åã„Çâ„Ç≠„Éº„ÇíÂèñÂæó
        key = st.secrets["GEMINI_API_KEY"]
        genai.configure(api_key=key)
        
        # „É¢„Éá„É´ÂÄôË£úÔºà2026Âπ¥ÁèæÂú®„ÅÆÂÆâÂÆöÁâàÔºâ
        for m_name in ["gemini-1.5-flash", "models/gemini-1.5-flash", "gemini-pro"]:
            try:
                m = genai.GenerativeModel(m_name)
                # ÁñéÈÄö„ÉÜ„Çπ„ÉàÔºà1„Éà„Éº„ÇØ„É≥„Å†„ÅëÁîüÊàêÔºâ
                m.generate_content("test", generation_config={"max_output_tokens": 1})
                return m
            except:
                continue
        return None
    except KeyError:
        st.error("Secrets„Å´ 'GEMINI_API_KEY' „ÅåÁôªÈå≤„Åï„Çå„Å¶„ÅÑ„Åæ„Åõ„Çì„ÄÇ")
        st.stop()
    except Exception as e:
        st.error(f"APIÂàùÊúüÂåñ‰∏≠„Å´„Ç®„É©„Éº: {e}")
        st.stop()

model = init_gemini()
if not model:
    st.error("APIÊé•Á∂ö„Å´Â§±Êïó„Åó„Åæ„Åó„Åü„ÄÇKey„ÅåÊúâÂäπ„Åã„ÄÅ„Åæ„Åü„ÅØGemini 1.5„ÅÆÂà©Áî®Ê®©Èôê„Åå„ÅÇ„Çã„ÅãÁ¢∫Ë™ç„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ")
    st.stop()

conn = st.connection("gsheets", type=GSheetsConnection)

if 'analyzed' not in st.session_state:
    st.session_state.analyzed = False
if 'ocr_data' not in st.session_state:
    st.session_state.ocr_data = {"cash": 0, "spot": 0, "margin": 0}

# --- 3. AIÂàÜÊûê„Ç®„É≥„Ç∏„É≥ ---
def perform_ai_analysis(up_file):
    p = 'ÊäΩÂá∫È†ÖÁõÆÔºö{"cash": Êï∞ÂÄ§, "spot": Êï∞ÂÄ§, "margin": Êï∞ÂÄ§}'
    try:
        img = Image.open(up_file)
        res = model.generate_content([p, img])
        j_str = re.search(r'\{.*\}', res.text, re.DOTALL).group()
        return json.loads(j_str)
    except: return None

@st.cache_data(ttl=3600)
def get_market_briefing(d_str, is_weekend):
    if is_weekend:
        p = f"‰ªäÊó•„ÅØ{d_str}(ÈÄ±Êú´)„ÄÇÂÖàÈÄ±„ÅÆÂ∏ÇÂ†¥ÊåØ„ÇäËøî„Çä„Å®ÊòéÊó•„Åã„Çâ„ÅÆÊåáÊ®ô„ÉªÊ≥®ÁõÆ„Ç§„Éô„É≥„Éà„ÇíÊó•Êú¨Ë™û„ÅßÁü≠„Åè„Åæ„Å®„ÇÅ„Å¶„ÄÇ"
    else:
        p = f"‰ªäÊó•„ÅØ{d_str}(Âπ≥Êó•)„ÄÇÊò®Êô©„ÅÆÁ±≥Ê†™„ÄÅÊú¨Êó•„ÅÆÊó•Êú¨Ê†™Ë¶ãÈÄö„Åó„ÄÅÈáçË¶ÅÊ±∫ÁÆó„ÉªÊåáÊ®ô„ÇíÊó•Êú¨Ë™û„ÅßÁü≠„Åè„Åæ„Å®„ÇÅ„Å¶„ÄÇ"
    try:
        res = model.generate_content(p)
        return res.text if res.text else "ÊÉÖÂ†±„ÅÆÂèñÂæóÂà∂Èôê‰∏≠"
    except:
        return "üí° „Éû„Éº„Ç±„ÉÉ„ÉàÊÉÖÂ†±„ÇíÊï¥ÁêÜ‰∏≠„ÄÇ„É™„É≠„Éº„Éâ„Çí„ÅäË©¶„Åó„Åè„Å†„Åï„ÅÑ„ÄÇ"

# --- 4. „Éá„Éº„ÇøË™≠„ÅøËæº„Åø ---
df_raw = pd.DataFrame()
try:
    df_raw = conn.read(spreadsheet=URL, ttl=0)
except:
    st.warning("„Çπ„Éó„É¨„ÉÉ„Éâ„Ç∑„Éº„ÉàÊé•Á∂öÂæÖ„Å°...")

# --- 5. „É°„Ç§„É≥ÁîªÈù¢ ---
st.title("üöÄ Wealth Navigator PRO")

if not df_raw.empty:
    df_raw['Êó•‰ªò'] = pd.to_datetime(df_raw['Êó•‰ªò'], errors='coerce')
    df_raw = df_raw.dropna(subset=['Êó•‰ªò'])
    df = df_raw.sort_values('Êó•‰ªò').drop_duplicates('Êó•‰ªò', keep='last').reset_index(drop=True)
    
    latest = df.iloc[-1]
    ld, total = latest['Êó•‰ªò'], latest['Á∑èË≥áÁî£']
    
    # ÊåáÊ®ôË®àÁÆó
    d_diff = total - df.iloc[-2]['Á∑èË≥áÁî£'] if len(df) > 1 else 0
    tm_df = df[df['Êó•‰ªò'].dt.to_period('M') == ld.to_period('M')]
    tm_diff = total - tm_df.iloc[0]['Á∑èË≥áÁî£'] if not tm_df.empty else 0
    
    # 1. „ÉÄ„ÉÉ„Ç∑„É•„Éú„Éº„Éâ
    st.subheader("üìä Ë≥áÁî£Áä∂Ê≥Å")
    cols = st.columns([1.2, 1, 1, 1, 1])
    with cols[0]:
        st.metric("Á∑èË≥áÁî£", f"¬•{int(total):,}")
        st.caption(f"‚î£ ÁèæÁâ©ÊôÇ‰æ°: ¬•{int(latest['ÁèæÁâ©ÊôÇ‰æ°Á∑èÈ°ç']):,}")
        st.caption(f"‚î£ ‰ø°Áî®ÊêçÁõä: ¬•{int(latest['‰ø°Áî®Ë©ï‰æ°ÊêçÁõä']):+,}")
        st.caption(f"‚îó Ë≤∑‰ªò‰ΩôÂäõ: ¬•{int(latest['ÁèæÁâ©Ë≤∑‰ªò‰ΩôÂäõ']):,}")
    
    cols[1].metric("ÁõÆÊ®ô„Åæ„Åß", f"¬•{int(GOAL - total):,}")
    cols[2].metric("ÂâçÊó•ÊØî", f"¬•{int(d_diff):,}", delta=f"{int(d_diff):+,}")
    cols[3].metric(f"{ld.month}ÊúàÂèéÊîØ", f"¬•{int(tm_diff):,}", delta=f"{int(tm_diff):+,}")
    cols[4].metric("ÈÅîÊàêÁéá", f"{total/GOAL:.2%}")
    
    st.progress(max(0.0, min(float(total / GOAL), 1.0)))

    # 2. ÂãïÁöÑ„Éû„Éº„Ç±„ÉÉ„Éà„ÉÄ„Ç§„Ç∏„Çß„Çπ„Éà
    st.divider()
    now = datetime.now()
    is_weekend = now.weekday() >= 5
    title = "üóìÔ∏è ÈÄ±Êú´„Éû„Éº„Ç±„ÉÉ„ÉàË¶ÅÁ¥Ñ" if is_weekend else "üìà Êú¨Êó•„ÅÆ„Éû„Éº„Ç±„ÉÉ„ÉàË¶ÅÁ¥Ñ"
    st.subheader(title)
    st.markdown(get_market_briefing(now.strftime('%Y-%m-%d'), is_weekend))

    # 3. „Ç∞„É©„Éï
    st.divider()
    vc, uc = st.columns([3, 1])
    with vc: st.write("### üèîÔ∏è Ë≥áÁî£„Éà„É¨„É≥„Éâ")
    with uc: v_mode = st.radio("Ë°®Á§∫", ["Êó•", "ÈÄ±", "Êúà"], horizontal=True)

    try:
        if v_mode == "Êó•":
            p_df = df[df['Êó•‰ªò'] >= (ld - timedelta(days=30))].copy()
            xf = "%m/%d"
        elif v_mode == "ÈÄ±":
            p_df = df.set_index('Êó•‰ªò').resample('W').last().dropna().reset_index()
            xf = "%m/%d"
        else:
            p_df = df.set_index('Êó•‰ªò').resample('M').last().dropna().reset_index()
            xf = "%y/%m"
        
        if p_df.empty: p_df = df.copy()

        y_m = p_df['Á∑èË≥áÁî£'].max() * 1.15
        fig = go.Figure()
        fig.add_trace(go.Scatter(
            x=p_df['Êó•‰ªò'], y=p_df['Á∑èË≥áÁî£'], fill='tozeroy', 
            line=dict(color='#007BFF', width=4), fillcolor='rgba(0, 123, 255, 0.15)',
            mode='lines+markers' if len(p_df) < 20 else 'lines'
        ))
        fig.update_layout(template="plotly_dark", height=400, margin=dict(l=50, r=20, t=20, b=50))
        fig.update_xaxes(tickformat=xf, type='date')
        fig.update_yaxes(range=[0, y_m], tickformat=",d")
        st.plotly_chart(fig, use_container_width=True)
    except:
        st.info("„Ç∞„É©„ÉïÁîüÊàê‰∏≠...")

else:
    st.info("„Éá„Éº„Çø„ÅåË™≠„ÅøËæº„ÇÅ„Åæ„Åõ„Çì„ÄÇ")

# --- 6. Êõ¥Êñ∞„Éï„Ç©„Éº„É† ---
st.divider()
st.subheader("üì∏ Ë≥áÁî£Êõ¥Êñ∞")
up_file = st.file_uploader("„Çπ„ÇØ„Ç∑„ÉßÈÅ∏Êäû", type=['png', 'jpg', 'jpeg'])

if st.button("AIËß£Êûê"):
    if up_file:
        with st.spinner('Ëß£Êûê‰∏≠...'):
            res = perform_ai_analysis(up_file)
            if res:
                st.session_state.ocr_data = res
                st.session_state.analyzed = True
                st.success("OK!")

if st.session_state.analyzed:
    with st.form("edit"):
        c1, c2, c3 = st.columns(3)
        ocr = st.session_state.ocr_data
        n_c = c1.number_input("‰ΩôÂäõ", value=int(ocr.get('cash', 0)))
        n_s = c2.number_input("ÊôÇ‰æ°", value=int(ocr.get('spot', 0)))
        n_m = c3.number_input("ÊêçÁõä", value=int(ocr.get('margin', 0)))
        if st.form_submit_button("Ë®òÈå≤"):
            td = datetime.now().strftime('%Y/%m/%d')
            tv = n_c + n_s + n_m
            ent = pd.DataFrame([{"Êó•‰ªò": td, "ÁèæÁâ©Ë≤∑‰ªò‰ΩôÂäõ": n_c, "ÁèæÁâ©ÊôÇ‰æ°Á∑èÈ°ç": n_s, "‰ø°Áî®Ë©ï‰æ°ÊêçÁõä": n_m, "Á∑èË≥áÁî£": tv, "1ÂÑÑÂÜÜ„Åæ„Åß„ÅÆÊÆã„Çä": GOAL - tv}])
            try:
                out = pd.concat([df_raw, ent], ignore_index=True) if not df_raw.empty else ent
                out['Êó•‰ªò'] = pd.to_datetime(out['Êó•‰ªò'])
                out = out.sort_values('Êó•‰ªò').drop_duplicates('Êó•‰ªò', keep='last')
                out['Êó•‰ªò'] = out['Êó•‰ªò'].dt.strftime('%Y/%m/%d')
                conn.update(spreadsheet=URL, data=out)
                st.balloons()
                st.session_state.analyzed = False
                st.rerun()
            except Exception as e:
                st.error(f"Error: {e}")
