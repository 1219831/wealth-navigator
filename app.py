import streamlit as st
from streamlit_gsheets import GSheetsConnection
import pandas as pd
from datetime import datetime, timedelta
import google.generativeai as genai
from PIL import Image
import json
import re
import plotly.graph_objects as go

# --- 1. åŸºæœ¬è¨­å®š ---
GOAL = 100000000 
URL = "https://docs.google.com/spreadsheets/d/1-Elv0TZJb6dVwHoGCx0fQinN2B1KYPOwWt0aWJEa_Is/edit"

st.set_page_config(page_title="Wealth Navigator PRO", page_icon="ğŸ“ˆ", layout="wide")

# --- 2. å¤–éƒ¨é€£æº ---
try:
    genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
    model = genai.GenerativeModel('models/gemini-1.5-flash')
except:
    st.error("APIè¨­å®šã‚¨ãƒ©ãƒ¼")
    st.stop()

conn = st.connection("gsheets", type=GSheetsConnection)

if 'analyzed' not in st.session_state:
    st.session_state.analyzed = False
if 'ocr_data' not in st.session_state:
    st.session_state.ocr_data = {"cash": 0, "spot": 0, "margin": 0}

# --- 3. AIåˆ†æã‚¨ãƒ³ã‚¸ãƒ³ ---
def perform_ai_analysis(up_file):
    p = 'æŠ½å‡ºé …ç›®ï¼š{"cash": æ•°å€¤, "spot": æ•°å€¤, "margin": æ•°å€¤}'
    try:
        img = Image.open(up_file)
        res = model.generate_content([p, img])
        j_str = re.search(r'\{.*\}', res.text, re.DOTALL).group()
        return json.loads(j_str)
    except: return None

@st.cache_data(ttl=3600)
def get_market_briefing(d_str):
    p = f"ä»Šæ—¥ã¯{d_str}ã€‚å…ˆé€±æœ«ã®ç±³æ ªæ—¥æœ¬æ ªæŒ¯ã‚Šè¿”ã‚Šã€æ˜æ—¥ã‹ã‚‰ã®å›½å†…æ±ºç®—ã€é‡è¦æŒ‡æ¨™ã€ğŸš¨é‡è¦ã‚¤ãƒ™ãƒ³ãƒˆã‚’æ—¥æœ¬èªã§ç°¡æ½”ã«ã¾ã¨ã‚ã¦ã€‚æŠ•è³‡åŠ©è¨€ã¯ä¸è¦ã€‚"
    try:
        res = model.generate_content(p)
        return res.text if res.text else "æƒ…å ±ã®å–å¾—ã‚’åˆ¶é™ä¸­"
    except: return "æ•´ç†ä¸­..."

# --- 4. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ ---
df_raw = pd.DataFrame()
try:
    df_raw = conn.read(spreadsheet=URL, ttl=0)
except:
    st.warning("ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆæ¥ç¶šå¾…ã¡...")

# --- 5. ãƒ¡ã‚¤ãƒ³è¡¨ç¤º ---
st.title("ğŸš€ Wealth Navigator PRO")

if not df_raw.empty:
    df_raw['æ—¥ä»˜'] = pd.to_datetime(df_raw['æ—¥ä»˜'], errors='coerce')
    df_raw = df_raw.dropna(subset=['æ—¥ä»˜'])
    df = df_raw.sort_values('æ—¥ä»˜').drop_duplicates('æ—¥ä»˜', keep='last').reset_index(drop=True)
    
    latest = df.iloc[-1]
    ld, total = latest['æ—¥ä»˜'], latest['ç·è³‡ç”£']
    
    # åæ”¯è¨ˆç®—ï¼ˆæ–­ç·šå¯¾ç­–ï¼šäº‹å‰ã«æ–‡å­—åˆ—åŒ–ï¼‰
    d_diff = total - df.iloc[-2]['ç·è³‡ç”£'] if len(df) > 1 else 0
    tm_df = df[df['æ—¥ä»˜'].dt.to_period('M') == ld.to_period('M')]
    tm_diff = total - tm_df.iloc[0]['ç·è³‡ç”£'] if not tm_df.empty else 0
    
    # è¡¨ç¤ºç”¨ã®ãƒ©ãƒ™ãƒ«ã¨å€¤ã‚’å¤‰æ•°åŒ–
    m_val = f"Â¥{int(total):,}"
    d_label = f"{ld.month}æœˆåæ”¯"
    d_val = f"Â¥{int(tm_diff):,}"
    d_delta = f"{int(tm_diff):+,}"

    st.subheader("ğŸ“Š è³‡ç”£çŠ¶æ³ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")
    cols = st.columns([1.2, 1, 1, 1, 1])
    with cols[0]:
        st.metric("ç¾åœ¨ã®ç·è³‡ç”£", m_val)
        st.caption(f"â”£ ç¾ç‰©è³‡ç”£æ™‚ä¾¡ç·é¡: Â¥{int(latest['ç¾ç‰©æ™‚ä¾¡ç·é¡']):,}")
        st.caption(f"â”£ ä¿¡ç”¨ä¿æœ‰è³‡ç”£æç›Š: Â¥{int(latest['ä¿¡ç”¨è©•ä¾¡æç›Š']):+,}")
        st.caption(f"â”— ç¾ç‰©å–å¾—ä½™åŠ›: Â¥{int(latest['ç¾ç‰©è²·ä»˜ä½™åŠ›']):,}")
    
    cols[1].metric("1å„„å††ã¾ã§", f"Â¥{int(GOAL - total):,}")
    cols[2].metric("å‰æ—¥æ¯”", f"Â¥{int(d_diff):,}", delta=f"{int(d_diff):+,}")
    cols[3].metric(d_label, d_val, delta=d_delta) # çŸ­æ–‡åŒ–ã§æ–­ç·šé˜²æ­¢
    cols[4].metric("ç›®æ¨™é”æˆç‡", f"{total/GOAL:.2%}")
    
    # é€²æ—ãƒãƒ¼
    prg_v = max(0.0, min(float(total / GOAL), 1.0))
    st.progress(prg_v)

    # AIãƒãƒ¼ã‚±ãƒƒãƒˆæƒ…å ±
    st.divider()
    st.subheader("ğŸ—“ï¸ é€±æœ«ãƒãƒ¼ã‚±ãƒƒãƒˆãƒ»ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆ")
    today_key = datetime.now().strftime('%Y-%m-%d')
    st.markdown(get_market_briefing(today_key))

    # ã‚°ãƒ©ãƒ•ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    st.divider()
    vc, uc = st.columns([3, 1])
    with vc: st.write("
