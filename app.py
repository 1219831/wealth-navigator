import streamlit as st
from streamlit_gsheets import GSheetsConnection
import pandas as pd
from datetime import datetime, timedelta
import google.generativeai as genai
from PIL import Image
import json
import re
import plotly.graph_objects as go

# --- 1. åŸºæœ¬è¨­å®š ---
GOAL = 100000000 
URL = "https://docs.google.com/spreadsheets/d/1-Elv0TZJb6dVwHoGCx0fQinN2B1KYPOwWt0aWJEa_Is/edit"

st.set_page_config(page_title="Wealth Navigator PRO", page_icon="ğŸ“ˆ", layout="wide")

# --- 2. å¤–éƒ¨é€£æº (ãƒ¢ãƒ‡ãƒ«åã‚’ãƒ•ãƒ«ãƒ‘ã‚¹ã§æŒ‡å®š) ---
try:
    genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
    model = genai.GenerativeModel('models/gemini-1.5-flash')
except Exception as e:
    st.error(f"APIåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
    st.stop()

conn = st.connection("gsheets", type=GSheetsConnection)

if 'analyzed' not in st.session_state:
    st.session_state.analyzed = False
if 'ocr_data' not in st.session_state:
    st.session_state.ocr_data = {"cash": 0, "spot": 0, "margin": 0}

# --- 3. AIåˆ†æã‚¨ãƒ³ã‚¸ãƒ³ ---
def perform_ai_analysis(up_file):
    p = 'æŠ½å‡ºï¼š{"cash": æ•°å€¤, "spot": æ•°å€¤, "margin": æ•°å€¤}'
    try:
        img = Image.open(up_file)
        res = model.generate_content([p, img])
        j_str = re.search(r'\{.*\}', res.text, re.DOTALL).group()
        return json.loads(j_str)
    except: return None

@st.cache_data(ttl=3600)
def get_market_briefing(d_str):
    # æ˜¨æ—¥ãƒ»ä»Šæ—¥ãƒ»æ˜æ—¥ã®3è»¸ã§æƒ…å ±ã‚’ç·©å’Œ
    p = f"""
    ä»Šæ—¥ã¯ {d_str}ï¼ˆæ—¥æ›œæ—¥ï¼‰ã§ã™ã€‚æŠ•è³‡å®¶å‘ã‘ã«ä»¥ä¸‹ã‚’æ—¥æœ¬èªã§ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚
    1. ã€å…ˆé€±æœ«ã®æŒ¯ã‚Šè¿”ã‚Šã€‘ï¼šç›´è¿‘ã®ç±³æ ªãƒ»æ—¥æœ¬æ ªã®ä¸»è¦ãªå‹•ãã€‚
    2. ã€æ˜æ—¥ã‹ã‚‰ã®æ³¨ç›®äºˆå®šã€‘ï¼šä»Šé€±ã®å›½å†…æ±ºç®—éŠ˜æŸ„ã¨é‡è¦çµŒæ¸ˆæŒ‡æ¨™ã€‚
    3. ã€ğŸš¨æœ€æ³¨ç›®ã‚¤ãƒ™ãƒ³ãƒˆã€‘ï¼šä»Šé€±ã€ç›¸å ´ã‚’å‹•ã‹ã™æœ€å¤§ã®è¦å› ã‚’å¤ªå­—ã§å¼·èª¿ã€‚
    â€»å…¬çŸ¥ã®æƒ…å ±ã®è¦ç´„ã¨ã—ã¦å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
    """
    try:
        res = model.generate_content(p)
        return res.text if res.text else "æƒ…å ±ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚"
    except Exception as e:
        return f"ğŸ’¡ æƒ…å ±ã‚’æ•´ç†ä¸­ã§ã™ã€‚ãƒªãƒ­ãƒ¼ãƒ‰ã‚’ãŠè©¦ã—ãã ã•ã„ã€‚({str(e)[:20]})"

# --- 4. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ & æ­£è¦åŒ– ---
df_raw = pd.DataFrame()
try:
    df_raw = conn.read(spreadsheet=URL, ttl=0)
except:
    st.warning("ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆæ¥ç¶šå¾…ã¡...")

# --- 5. ãƒ¡ã‚¤ãƒ³è¡¨ç¤º ---
st.title("ğŸš€ Wealth Navigator PRO")

if not df_raw.empty:
    # å¾¹åº•çš„ãªãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
    df_raw['æ—¥ä»˜'] = pd.to_datetime(df_raw['æ—¥ä»˜'], errors='coerce')
    df_raw = df_raw.dropna(subset=['æ—¥ä»˜'])
    df = df_raw.sort_values('æ—¥ä»˜').drop_duplicates('æ—¥ä»˜', keep='last').reset_index(drop=True)
    
    latest = df.iloc[-1]
    ld, total = latest['æ—¥ä»˜'], latest['ç·è³‡ç”£']
    
    # æŒ‡æ¨™è¨ˆç®—
    d_diff = total - df.iloc[-2]['ç·è³‡ç”£'] if len(df) > 1 else 0
    tm_df = df[df['æ—¥ä»˜'].dt.to_period('M') == ld.to_period('M')]
    tm_diff = total - tm_df.iloc[0]['ç·è³‡ç”£'] if not tm_df.empty else 0

    # ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
    st.subheader("ğŸ“Š è³‡ç”£çŠ¶æ³ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")
    cols = st.columns([1.2, 1, 1, 1, 1])
    with cols[0]:
        st.metric("ç¾åœ¨ã®ç·è³‡ç”£", f"Â¥{int(total):,}")
        st.caption(f"â”£ ç¾ç‰©è³‡ç”£æ™‚ä¾¡ç·é¡: Â¥{int(latest['ç¾ç‰©æ™‚ä¾¡ç·é¡']):,}")
        st.caption(f"â”£ ä¿¡ç”¨ä¿æœ‰è³‡ç”£æç›Š: Â¥{int(latest['ä¿¡ç”¨è©•ä¾¡æç›Š']):+,}")
        st.caption(f"â”— ç¾ç‰©å–å¾—ä½™åŠ›: Â¥{int(latest['ç¾ç‰©è²·ä»˜ä½™åŠ›']):,}")
    
    cols[1].metric("1å„„å††ã¾ã§", f"Â¥{int(GOAL - total):,}")
    cols[2].metric("å‰æ—¥æ¯”", f"Â¥{int(d_diff):,}", delta=f"{int(d_diff):+,}")
    cols[3].metric(f"{ld.month}æœˆåæ”¯", f"Â¥{int(tm_diff):,}", delta=f"{int(tm_diff):+,}")
    cols[4].metric("ç›®æ¨™é”æˆç‡", f"{total/GOAL:.2%}")
    st.progress(max(0.0
