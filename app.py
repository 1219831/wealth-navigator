import streamlit as st
from streamlit_gsheets import GSheetsConnection
import pandas as pd
from datetime import datetime, timedelta
import google.generativeai as genai
from PIL import Image
import json
import re
import plotly.graph_objects as go

# --- 1. åŸºæœ¬è¨­å®š ---
GOAL = 100000000 
URL = "https://docs.google.com/spreadsheets/d/1-Elv0TZJb6dVwHoGCx0fQinN2B1KYPOwWt0aWJEa_Is/edit"

st.set_page_config(page_title="Wealth Navigator PRO", page_icon="ğŸ“ˆ", layout="wide")

# --- 2. å¤–éƒ¨é€£æº ---
try:
    genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
    # æ¥ç¶šã®å®‰å®šæ€§ã‚’é«˜ã‚ã‚‹ãƒ•ãƒ«ãƒ‘ã‚¹æŒ‡å®š
    model = genai.GenerativeModel('models/gemini-1.5-flash')
except Exception as e:
    st.error(f"APIè¨­å®šã‚¨ãƒ©ãƒ¼: {e}")
    st.stop()

conn = st.connection("gsheets", type=GSheetsConnection)

if 'analyzed' not in st.session_state:
    st.session_state.analyzed = False
if 'ocr_data' not in st.session_state:
    st.session_state.ocr_data = {"cash": 0, "spot": 0, "margin": 0}

# --- 3. AIæ©Ÿèƒ½ ---
def perform_ai_analysis(up_file):
    p = 'æŠ½å‡ºï¼š{"cash": æ•°å€¤, "spot": æ•°å€¤, "margin": æ•°å€¤}'
    try:
        img = Image.open(up_file)
        res = model.generate_content([p, img])
        j_str = re.search(r'\{.*\}', res.text, re.DOTALL).group()
        return json.loads(j_str)
    except: return None

@st.cache_data(ttl=3600)
def get_market_briefing(date_str):
    prompt = f"""
    ä»Šæ—¥ã¯ {date_str} ã§ã™ã€‚ä»¥ä¸‹ã®æŠ•è³‡æƒ…å ±ã‚’æ—¥æœ¬èªã§ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚
    â– å›½å†…æ±ºç®—ï¼šæœ¬æ—¥ã®æ³¨ç›®éŠ˜æŸ„ã¨ç™ºè¡¨ä»¶æ•°
    â– é‡è¦æŒ‡æ¨™ï¼šæ—¥ãƒ»ç±³ãƒ»æ¬§ãƒ»ä¸­ã®çµŒæ¸ˆæŒ‡æ•°
    â– ç‰¹è¨˜äº‹é …ï¼šğŸš¨ç‰¹ã«é‡è¦ãªã‚¤ãƒ™ãƒ³ãƒˆã¯å¤ªå­—ã§å¼·èª¿ã€‚
    â€»æŠ•è³‡åŠ©è¨€ã§ã¯ãªãå®¢è¦³çš„ãªäºˆå®šè¡¨ã¨ã—ã¦å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
    """
    try:
        response = model.generate_content(prompt)
        return response.text if response.text else "æƒ…å ±ã®å–å¾—ã‚’åˆ¶é™ä¸­"
    except Exception as e:
        return f"ğŸ’¡ æº–å‚™ä¸­ (API Wait: {str(e)[:20]})"

# --- 4. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ ---
df_raw = pd.DataFrame()
try:
    df_raw = conn.read(spreadsheet=URL, ttl=0)
except:
    st.warning("ã‚·ãƒ¼ãƒˆæ¥ç¶šå¾…ã¡...")

# --- 5. ãƒ¡ã‚¤ãƒ³è¡¨ç¤º ---
st.title("ğŸš€ Wealth Navigator PRO")

if not df_raw.empty:
    df_raw['æ—¥ä»˜'] = pd.to_datetime(df_raw['æ—¥ä»˜']).dt.normalize()
    df = df_raw.sort_values('æ—¥ä»˜').drop_duplicates('æ—¥ä»˜', keep='last').reset_index(drop=True)
    
    latest = df.iloc[-1]
    ld, total = latest['æ—¥ä»˜'], latest['ç·è³‡ç”£']
    
    # 1. ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
    st.subheader("ğŸ“Š è³‡ç”£çŠ¶æ³ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")
    cols = st.columns([1.2, 1, 1, 1, 1])
    with cols[0]:
        st.metric("ç¾åœ¨ã®ç·è³‡ç”£", f"Â¥{int(total):,}")
        st.caption(f"â”£ ç¾ç‰©è³‡ç”£æ™‚ä¾¡ç·é¡: Â¥{int(latest['ç¾ç‰©æ™‚ä¾¡ç·é¡']):,}")
        st.caption(f"â”£ ä¿¡ç”¨ä¿æœ‰è³‡ç”£æç›Š: Â¥{int(latest['ä¿¡ç”¨è©•ä¾¡æç›Š']):+,}")
        st.caption(f"â”— ç¾ç‰©å–å¾—ä½™åŠ›: Â¥{int(latest['ç¾ç‰©è²·ä»˜ä½™åŠ›']):,}")
    
    # æŒ‡æ¨™è¨ˆç®—ï¼ˆå®‰å…¨ãªè¤‡æ•°è¡Œå‡¦ç†ï¼‰
    d_diff = 0
    if len(df) > 1:
        d_diff = total - df.iloc[-2]['ç·è³‡ç”£']
    
    tm_df = df[df['æ—¥ä»˜'].dt.to_period('M') == ld.to_period('M')]
    tm_diff = total - tm_df.iloc[0]['ç·è³‡ç”£'] if not tm_df.empty else 0
    
    lm_target = ld.replace(day=1) - timedelta(days=1)
    lm_df = df[df['æ—¥ä»˜'].dt.to_period('M') == lm_target.to_period('M')]
    lm_diff = lm_df.iloc[-1]['ç·è³‡ç”£'] - lm_df.iloc[0]['ç·è³‡ç”£'] if not lm_df.empty else 0

    cols[1].metric("1å„„å††ã¾ã§", f"Â¥{int(GOAL - total):,}")
    cols[2].metric("å‰æ—¥æ¯”", f"Â¥{int(d_diff):,}", delta=f"{int(d_diff):+,}")
    cols[3].metric(f"{lm_target.month}æœˆåæ”¯", f"Â¥{int(lm_diff):,}", delta=f"{int(lm_diff):+,}")
    cols[4].metric(
